{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaturalLanguage.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7_aAiBatcyb"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcIMf_MOt0Tx",
        "outputId": "44254341-02c0-4d5c-99f7-6c79f5b2de88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HflCw184tpDt"
      },
      "source": [
        "text = \"Natural language processing (NLP) is a field \" \\\n",
        "       + \"of computer science, artificial intelligence \" \\\n",
        "       + \"and computational linguistics concerned with \" \\\n",
        "       +\"the interactions between computers and human \" \\\n",
        "       + \"(natural) languages, and, in particular, \" \\\n",
        "       + \"concerned with programming computers to \" \\\n",
        "       + \"fruitfully process large natural language \" \\\n",
        "       + \"corpora. Challenges in natural language \" \\\n",
        "       + \"processing frequently involve natural \" \\\n",
        "       + \"language understanding, natural language \" \\\n",
        "       + \"generation frequently from formal, machine\" \\\n",
        "       + \"-readable logical forms), connecting language \" \\\n",
        "       + \"and machine perception, managing human-\" \\\n",
        "       + \"computer dialog systems, or some combination \" \\\n",
        "       + \"thereof. There are 365 days usually. \" \\\n",
        "       + \"This year is 2020.\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emXoDZtbtuqU",
        "outputId": "3a5dbb77-c948-482d-dd15-87df737ee26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(sent_tokenize(text)) \n",
        "print('\\n')\n",
        "print(word_tokenize(text))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Natural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora.', 'Challenges in natural language processing frequently involve natural language understanding, natural language generation frequently from formal, machine-readable logical forms), connecting language and machine perception, managing human-computer dialog systems, or some combination thereof.', 'There are 365 days usually.', 'This year is 2020.']\n",
            "\n",
            "\n",
            "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'and', ',', 'in', 'particular', ',', 'concerned', 'with', 'programming', 'computers', 'to', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', '.', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', ',', 'natural', 'language', 'generation', 'frequently', 'from', 'formal', ',', 'machine-readable', 'logical', 'forms', ')', ',', 'connecting', 'language', 'and', 'machine', 'perception', ',', 'managing', 'human-computer', 'dialog', 'systems', ',', 'or', 'some', 'combination', 'thereof', '.', 'There', 'are', '365', 'days', 'usually', '.', 'This', 'year', 'is', '2020', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sed0Eq90txCs"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "#\n",
        "tokens = word_tokenize(text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsxiEsWqulEj",
        "outputId": "bccb45d9-0fe9-4fff-c053-eace84cce48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tokens = [token.lower() for token in tokens]\n",
        "print(tokens)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natural', 'language', 'processing', '(', 'nlp', ')', 'is', 'a', 'field', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'and', ',', 'in', 'particular', ',', 'concerned', 'with', 'programming', 'computers', 'to', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', '.', 'challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', ',', 'natural', 'language', 'generation', 'frequently', 'from', 'formal', ',', 'machine-readable', 'logical', 'forms', ')', ',', 'connecting', 'language', 'and', 'machine', 'perception', ',', 'managing', 'human-computer', 'dialog', 'systems', ',', 'or', 'some', 'combination', 'thereof', '.', 'there', 'are', '365', 'days', 'usually', '.', 'this', 'year', 'is', '2020', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJlaBOxvuoJa",
        "outputId": "eeb9b43c-b3a6-4231-c773-3901029aaf59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import re\n",
        "# digitos\n",
        "tokens = [re.sub(r'\\d+', '',token) for token in tokens]\n",
        "# parÃ©ntesis\n",
        "tokens = [re.sub(r'[()]', '',token) for token in tokens]\n",
        "print(tokens)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natural', 'language', 'processing', '', 'nlp', '', 'is', 'a', 'field', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '', 'natural', '', 'languages', ',', 'and', ',', 'in', 'particular', ',', 'concerned', 'with', 'programming', 'computers', 'to', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', '.', 'challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', ',', 'natural', 'language', 'generation', 'frequently', 'from', 'formal', ',', 'machine-readable', 'logical', 'forms', '', ',', 'connecting', 'language', 'and', 'machine', 'perception', ',', 'managing', 'human-computer', 'dialog', 'systems', ',', 'or', 'some', 'combination', 'thereof', '.', 'there', 'are', '', 'days', 'usually', '.', 'this', 'year', 'is', '', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkHNNqC4vE6k",
        "outputId": "13e047b4-8a73-47fb-9596-777132ce79e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tokens_4 = []\n",
        "for token in tokens:\n",
        "    if len(token) > 3:\n",
        "        tokens_4.append(token)\n",
        "tokens = tokens_4\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natural', 'language', 'processing', 'field', 'computer', 'science', 'artificial', 'intelligence', 'computational', 'linguistics', 'concerned', 'with', 'interactions', 'between', 'computers', 'human', 'natural', 'languages', 'particular', 'concerned', 'with', 'programming', 'computers', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', 'challenges', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', 'natural', 'language', 'generation', 'frequently', 'from', 'formal', 'machine-readable', 'logical', 'forms', 'connecting', 'language', 'machine', 'perception', 'managing', 'human-computer', 'dialog', 'systems', 'some', 'combination', 'thereof', 'there', 'days', 'usually', 'this', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOEJKb8avIbA",
        "outputId": "3d8cd1dc-794b-4147-dcd6-c1ad4e68396a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import gensim\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "#\n",
        "stop_words_g = []\n",
        "for token  in gensim.parsing.preprocessing.STOPWORDS:\n",
        "    stop_words_g.append(token)\n",
        "print(stop_words_g)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['either', 'show', 'would', 'though', 'via', 'among', 'sincere', 'front', 'less', 'themselves', 'empty', 'not', 'namely', 'should', 'two', 'ours', 'regarding', 'next', 'eg', 'just', 'something', 'during', 'somehow', 'thereupon', 'side', 'towards', 'up', 're', 'afterwards', 'almost', 'when', 'see', 'whenever', 'any', 'without', 'perhaps', 'go', 'hereby', 'ie', 'across', 'these', 'therein', 'interest', 'other', 'upon', 'con', 'move', 'onto', 'twelve', 'last', 'hasnt', 'under', 'elsewhere', 'been', 'much', 'am', 'etc', 'another', 'become', 'except', 'top', 'a', 'anything', 'anyhow', 'their', 'alone', 'below', 'or', 'whither', 'with', 'unless', 'else', 'none', 'only', 'toward', 'each', 'bottom', 'per', 'have', 'most', 'few', 'ltd', 'to', 'hence', 'forty', 'due', 'my', 'give', 'does', 'ever', 'latter', 'myself', 'over', 'where', 'un', 'ourselves', 'hereupon', 'why', 'could', 'however', 'against', 'then', 'of', 'itself', 'she', 'mine', 'seemed', 'an', 'can', 'made', 'besides', 'has', 'co', 'amount', 'various', 'nor', 'our', 'couldnt', 'call', 'what', 'but', 'formerly', 'whom', 'find', 'twenty', 'on', 'more', 'seems', 'please', 'although', 'from', 'system', 'whence', 'off', 'again', 'make', 'very', 'even', 'here', 'fire', 'former', 'were', 'such', 'did', 'never', 'mill', 'there', 'hereafter', 'some', 'as', 'before', 'those', 'down', 'sometimes', 'now', 'together', 'describe', 'someone', 'we', 'became', 'through', 'they', 'still', 'had', 'within', 'after', 'first', 'sixty', 'both', 'throughout', 'nevertheless', 'put', 'part', 'often', 'keep', 'wherever', 'yet', 'because', 'detail', 'enough', 'back', 'no', 'meanwhile', 'this', 'four', 'kg', 'your', 'yourselves', 'beyond', 'at', 'it', 'full', 'everyone', 'computer', 'whatever', 'herein', 'are', 'hundred', 'whereas', 'inc', 'didn', 'three', 'will', 'quite', 'wherein', 'if', 'being', 'cry', 'mostly', 'the', 'do', 'which', 'indeed', 'who', 'otherwise', 'bill', 'his', 'was', 'fify', 'thereby', 'nobody', 'once', 'cant', 'third', 'five', 'between', 'and', 'get', 'for', 'its', 'himself', 'yourself', 'nine', 'sometime', 'everywhere', 'until', 'also', 'moreover', 'cannot', 'doesn', 'whereby', 'in', 'thereafter', 'seem', 'so', 'him', 'while', 'too', 'rather', 'already', 'latterly', 'several', 'further', 'always', 'by', 'serious', 'amoungst', 'along', 'many', 'hers', 'he', 'becoming', 'her', 'doing', 'whose', 'eleven', 'thus', 'how', 'whoever', 'own', 'all', 'everything', 'used', 'neither', 'whereafter', 'is', 'that', 'since', 'behind', 'name', 'be', 'least', 'anywhere', 'beforehand', 'you', 'anyone', 'using', 'therefore', 'me', 'might', 'say', 'may', 'whole', 'found', 'whether', 'into', 'becomes', 'i', 'nowhere', 'thence', 'one', 'herself', 'nothing', 'yours', 'take', 'fifteen', 'done', 'well', 'don', 'six', 'them', 'km', 'whereupon', 'amongst', 'us', 'around', 'fill', 'thin', 'beside', 'eight', 'de', 'noone', 'than', 'really', 'ten', 'out', 'anyway', 'every', 'seeming', 'thru', 'thick', 'above', 'about', 'others', 'same', 'must', 'somewhere']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUYBbCnEvKtB",
        "outputId": "812432d4-9957-406c-9a35-9d1d49e95b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "#\n",
        "stopWords = set(stopwords.words('english'))\n",
        "#\n",
        "print(stopWords)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"shouldn't\", 'themselves', 'not', 'should', 'wasn', 'ours', 'just', 'during', \"that'll\", 'll', 're', 'up', 'when', 'shan', 'any', 'these', 'needn', 'other', \"mightn't\", 'd', 't', 'under', \"don't\", 'am', 'been', 'a', 'their', 'with', 'below', 'or', \"you've\", 'only', 'y', 'have', 'each', 's', 'most', \"mustn't\", 'few', 'to', \"doesn't\", 'my', \"hadn't\", 'does', 'myself', 'over', 'where', 'ourselves', 'why', \"wouldn't\", 'won', 'against', 'of', 'itself', 'then', 'she', 'an', 'can', \"weren't\", 'has', \"you'd\", 'nor', 'our', 'but', 'what', 'whom', 'on', 'more', 'wouldn', 'off', 'from', 'again', \"you're\", 'here', 'very', 'were', 'such', 'did', 'there', 'some', 'as', 'weren', 'before', 'those', 'down', 'now', 'after', 'we', 'ain', 'they', 'through', 'had', 'both', \"aren't\", \"hasn't\", 'theirs', 'because', 'hasn', 'no', 'this', 'at', 'your', 'yourselves', 'ma', 'it', 'are', 'didn', 'will', 'if', 'isn', 'being', 'mustn', 'the', 'which', 'do', \"shan't\", 'who', 'o', \"couldn't\", \"it's\", 'his', 've', 'was', 'once', 'and', 'between', 'himself', 'its', 'for', 'yourself', 'until', \"won't\", 'doesn', 'in', 'so', 'him', 'while', 'too', \"haven't\", \"didn't\", 'by', 'further', \"should've\", 'having', 'he', 'hers', 'haven', 'her', 'doing', 'how', 'all', 'own', 'that', \"needn't\", 'is', 'be', \"isn't\", \"wasn't\", 'hadn', 'you', 'mightn', 'me', 'shouldn', 'i', 'into', 'herself', 'aren', 'yours', 'don', 'them', 'm', 'couldn', 'than', 'out', \"you'll\", 'above', 'about', \"she's\", 'same'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XLh6ctpvNy-",
        "outputId": "cf263279-f0f0-4c5c-b869-e9996d71198e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(tokens)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natural', 'language', 'processing', 'field', 'computer', 'science', 'artificial', 'intelligence', 'computational', 'linguistics', 'concerned', 'with', 'interactions', 'between', 'computers', 'human', 'natural', 'languages', 'particular', 'concerned', 'with', 'programming', 'computers', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', 'challenges', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', 'natural', 'language', 'generation', 'frequently', 'from', 'formal', 'machine-readable', 'logical', 'forms', 'connecting', 'language', 'machine', 'perception', 'managing', 'human-computer', 'dialog', 'systems', 'some', 'combination', 'thereof', 'there', 'days', 'usually', 'this', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Uu3OvpvRsR",
        "outputId": "513ef865-01b2-4950-d425-a5aeecfb6bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tokens_n_e = []\n",
        "\n",
        "for token in tokens:\n",
        "    if token not in stopWords:\n",
        "        tokens_n_e.append(token)\n",
        "#\n",
        "tokens = tokens_n_e\n",
        "print(tokens) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natural', 'language', 'processing', 'field', 'computer', 'science', 'artificial', 'intelligence', 'computational', 'linguistics', 'concerned', 'interactions', 'computers', 'human', 'natural', 'languages', 'particular', 'concerned', 'programming', 'computers', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', 'challenges', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', 'natural', 'language', 'generation', 'frequently', 'formal', 'machine-readable', 'logical', 'forms', 'connecting', 'language', 'machine', 'perception', 'managing', 'human-computer', 'dialog', 'systems', 'combination', 'thereof', 'days', 'usually', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v38ER9ZnvTTd",
        "outputId": "ac54c3f3-a2ec-4aa0-eba2-e9181c956da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "  \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "  \n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
        "  \n",
        "# a denotes adjective in \"pos\" \n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3wfGImevWjk",
        "outputId": "38d1cef5-8b0a-4575-daf4-2a71727aa08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "#\n",
        "# verbs\n",
        "lemma_text =[]\n",
        "for token in tokens:\n",
        "    lemma_text.append(WordNetLemmatizer().lemmatize(token, pos='v'))\n",
        "\n",
        "print(tokens)\n",
        "print('\\n')\n",
        "print(lemma_text)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natural', 'language', 'processing', 'field', 'computer', 'science', 'artificial', 'intelligence', 'computational', 'linguistics', 'concerned', 'interactions', 'computers', 'human', 'natural', 'languages', 'particular', 'concerned', 'programming', 'computers', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', 'challenges', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', 'natural', 'language', 'generation', 'frequently', 'formal', 'machine-readable', 'logical', 'forms', 'connecting', 'language', 'machine', 'perception', 'managing', 'human-computer', 'dialog', 'systems', 'combination', 'thereof', 'days', 'usually', 'year']\n",
            "\n",
            "\n",
            "['natural', 'language', 'process', 'field', 'computer', 'science', 'artificial', 'intelligence', 'computational', 'linguistics', 'concern', 'interactions', 'computers', 'human', 'natural', 'languages', 'particular', 'concern', 'program', 'computers', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', 'challenge', 'natural', 'language', 'process', 'frequently', 'involve', 'natural', 'language', 'understand', 'natural', 'language', 'generation', 'frequently', 'formal', 'machine-readable', 'logical', 'form', 'connect', 'language', 'machine', 'perception', 'manage', 'human-computer', 'dialog', 'systems', 'combination', 'thereof', 'days', 'usually', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg9bl6LGvZ4D",
        "outputId": "99774ae9-db8b-4ec4-ed42-b13d638d4fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# nouns\n",
        "for i in range(len(lemma_text )):\n",
        "    lemma_text[i] = WordNetLemmatizer().lemmatize(lemma_text[i], pos='n')\n",
        "print(lemma_text)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natural', 'language', 'process', 'field', 'computer', 'science', 'artificial', 'intelligence', 'computational', 'linguistics', 'concern', 'interaction', 'computer', 'human', 'natural', 'language', 'particular', 'concern', 'program', 'computer', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpus', 'challenge', 'natural', 'language', 'process', 'frequently', 'involve', 'natural', 'language', 'understand', 'natural', 'language', 'generation', 'frequently', 'formal', 'machine-readable', 'logical', 'form', 'connect', 'language', 'machine', 'perception', 'manage', 'human-computer', 'dialog', 'system', 'combination', 'thereof', 'day', 'usually', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKCFQqrDvdC6",
        "outputId": "9d8fa9be-74b6-4109-a343-d17b0d794ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import PorterStemmer \n",
        "# crea una instancia de PorterStemmer \n",
        "ps = PorterStemmer()\n",
        "\n",
        "for i in range(len(lemma_text)):\n",
        "    lemma_text[i] = ps.stem(lemma_text[i])\n",
        "print(lemma_text)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natur', 'languag', 'process', 'field', 'comput', 'scienc', 'artifici', 'intellig', 'comput', 'linguist', 'concern', 'interact', 'comput', 'human', 'natur', 'languag', 'particular', 'concern', 'program', 'comput', 'fruit', 'process', 'larg', 'natur', 'languag', 'corpu', 'challeng', 'natur', 'languag', 'process', 'frequent', 'involv', 'natur', 'languag', 'understand', 'natur', 'languag', 'gener', 'frequent', 'formal', 'machine-read', 'logic', 'form', 'connect', 'languag', 'machin', 'percept', 'manag', 'human-comput', 'dialog', 'system', 'combin', 'thereof', 'day', 'usual', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0LtMGksvfM_"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7pMhyzXvl-x"
      },
      "source": [
        "from nltk.stem import PorterStemmer \n",
        "\n",
        "def lemmatize_stemming(text):\n",
        "    ps = PorterStemmer()\n",
        "    return ps.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text): #  gensim.utils.simple_preprocess tokeniza el texto\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoz03uVQvpgK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}